# Kubernetes Terraform Project - On-Prem Workloads

## 🚀 Overview
This project leverages **Terraform** to orchestrate application workloads on an existing **Kubernetes cluster** (on-premises or cloud-managed), entirely without traditional YAML manifests.  
All Kubernetes resources are provisioned via the **Terraform `kubernetes_*` provider**, enabling a complete Infrastructure-as-Code (IaC) approach for managing Kubernetes workloads.

> 🚧 **Note:** This project is still ongoing and actively being improved with additional features and optimizations.

## 🔧 What does this project deploy?
✅ **Namespace**
- Creates a dedicated `dev` namespace in your cluster.

✅ **Deployments**
- **Frontend**: an `nginx` deployment with 3 replicas.
- **Backend**: an `httpd` (Apache) deployment with 3 replicas.
- **Database**: a `redis` deployment with 3 replicas.
- Each deployment has clearly defined **CPU and Memory requests & limits** to ensure predictable resource allocation.
- Utilizes **node affinity** and **tolerations** to schedule pods on specific nodes based on `tier` labels (e.g., `frontend-backend`, `database`).

✅ **Services**
- Each workload has its own `ClusterIP` Service for internal communication:
  - `frontend:80`
  - `backend:80`
  - `database:6379`
- Additionally, there's a `NodePort` Service on port `30080` for the frontend, exposing it externally via the worker nodes’ IP addresses.

✅ **ConfigMaps & Secrets**

- Manages Kubernetes ConfigMaps to inject environment variables into the nginx containers (e.g. ENVIRONMENT and APP_VERSION).
- Creates Secrets to securely store sensitive data like the REDIS_PASSWORD for the redis deployment.

✅ **Horizontal Pod Autoscaler**
- Configured for both frontend and backend deployments.
- Automatically scales pods between 3 and 7 replicas based on CPU and Memory utilization thresholds set at 50%.

✅ **Vertical Pod Autoscaler**
- Configured for the database (redis) deployment.
- Automatically adjusts recommended CPU and Memory requests within defined minAllowed and maxAllowed resource constraints.

✅ **Priority Classes**
- Introduced two PriorityClass resources:
    1. frontendbackend with a value of 1000, applied to frontend and backend workloads.
    2. database with a value of 100000, giving highest scheduling priority to the database pods.
- These priority classes ensure critical workloads (like Redis) are scheduled first when cluster resources are constrained.
- Applied via the priority_class_name attribute in Terraform deployments for better pod scheduling control.


> 📌 **Note:**  
> HPA and VPA are implemented via native YAML manifests as a best practice for workload-level scaling.
> This approach avoids provider-specific HCL complexities and aligns with common industry patterns,
> keeping Terraform focused on cluster infrastructure while scaling policies remain flexible and easily adjustable.

## ⚙️ How to use
### Prerequisites
- Existing Kubernetes cluster
- Terraform installed

### Deploy the infrastructure
```bash
terraform init
terraform plan
terraform apply



VPA and HPA needs to be deployed manually: 
cd ~/kubernetes
kubectl apply -f vpa.yaml
kubectl apply -f hpa.yaml


Nodes preparations (labels & taints)
kubectl label node minikube-m02 tier=frontend-backend
kubectl label node minikube-m03 tier=database
kubectl taint nodes minikube-m02 tier=frontend-backend:NoExecute
kubectl taint nodes minikube-m03 tier=database:NoExecute